{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b85fb-15ef-40a8-8063-ad97357abb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8253c72-8b3d-45ba-9735-ef57a6a20227",
   "metadata": {},
   "source": [
    "## âœ… Week 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ 1. Data Integrity & Structure\n",
    "\n",
    "Q: Are there any missing, duplicate, or incorrectly formatted entries in the dataset?  \n",
    "A: No missing values were found in the dataset, as 253680 instances are complete.\n",
    "   24206 rows (corresponding to 9.5% of the dataset) were identified as duplicates and would be further assessed for removal to ensure each observation is unique and does not bias the model.\n",
    "   No formatting issues were observed; however, all features were stored as float64, while many of them should be integers or categories.\n",
    "    \n",
    "Q: Are all data types appropriate (e.g., numeric, categorical)?  \n",
    "A: No, not all data types are appropriate in the raw dataset. The appropriate format is given below\n",
    "   Binary categorical Features: 15 Columns: Outcome, Sex, HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, DiffWalk\n",
    "   ordinal/categorical_features: 4 Columns: ['GenHlth', 'Age', 'Education', 'Income']\n",
    "   numeric_features: 3 Columns ['BMI', 'MentHlth', 'PhysHlth']\n",
    "   While some features like BMI, mental health, and physical health are naturally numeric and stored as float, other columns are binary or ordinal categorical and needed to be converted into the appropriate datatype (category or int) to reduce memory usage. \n",
    "   Binary categorical variables were misrepresented as continuous (float).\n",
    "   Ordinal numeric/categorical variables lost their semantic meaning.\n",
    "   Therefore, the data types were not initially appropriate, and needed explicit correction based on domain knowledge\n",
    "\n",
    "Q: Did you detect any constant, near-constant, or irrelevant features?  \n",
    "A: No constant features (i.e., columns with only one unique value) were detected. Every feature had at least two unique values, indicating variability     in responses.\n",
    "   There are a few features that showed near-constant behavior, where one category accounted for the vast majority of entries. For example\n",
    "   CholCheck                   96.27%      \n",
    "   Stroke                      95.94      \n",
    "   AnyHealthcare               95.11      \n",
    "These features are not removed immediately but flagged for possible exclusion or dimensionality reduction if they do not significantly contribute during model evaluation.\n",
    "Initially, there are no clear indications of irrelevant features. All retained features may have potential predictive power for diabetes classification and should be evaluated during model training for importance.\n",
    "\n",
    "---\n",
    "### ðŸŽ¯ 2. Target Variable Assessment \n",
    "Q: What is the distribution of `Diabetes_binary`?  \n",
    "A: The distribution of target_class is highly imbalanced, with class 0 (no diabetes) comprising approximately 86% of the data (218334 instances), class 1 (prediabetes or diabetes) accounting for 14.0% (35,346 instances). This suggests a strong class skew that may require addressing in modelling.\n",
    "\n",
    "Q: Is there a class imbalance? If so, how significant is it?  \n",
    "A: Yes, there is a significant class imbalance. Class 0 dominates the dataset with approximately 86.07% of the instances (218334 out of 253,680), while class 1 accounts for 13.930% (35,346 instances), and class 1 comprises only 1.8% (4,631 instances). The disparity between the majority and minority classes is substantial and may adversely affect model performance (due to algorithmic bias) if not addressed\n",
    "\n",
    "Q: How might this imbalance influence your choice of evaluation metrics or model strategy?  \n",
    "A: The imbalance makes it important to use balanced evaluation metrics (such as precision, recall, F1-score, and area under the precision-recall curve) and model strategies that ensure fair learning across all classes. Ignoring this can lead to a model that performs poorly on critical minority outcomes, which is unacceptable in sensitive domains like healthcare.\n",
    "We may have to consider resampling methods such as SMOTE, ADASYN, oversampling, undersampling or class weighting.\n",
    "We may have to consider threshold tuning to optimise recall or the F1 score, depending on the clinical priority\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š 3. Feature Distribution & Quality\n",
    "\n",
    "Q: Which numerical features are skewed or contain outliers?  \n",
    "A:  MentHlth has strong positive skew (~2.72) with many zeros: about 14% flagged as outliers.\n",
    "    PhysHlth is positively skewed (~2.21) with about 16% flagged as outliers\n",
    "    BMI: Right skewed (2.12) with a long tail: 3.9% flagged as outlier, and the maximum observed at 98.\n",
    "    \n",
    "Q: Did any features contain unrealistic or problematic values?\n",
    "A:  MentHlth and PhysHlth are within the 0-30 days. No negative or >30\n",
    "    BMI: No negatives or <10; however, 279 observations > 80 were flagged. Such values can be physiologically rare and may warrant verification or          capping.\n",
    "    \n",
    "\n",
    "Q: What transformation methods (if any) might improve these feature distributions?  \n",
    "A:  MentHlth and PhysHlth: Yeo-Johnson or Square-root transformation for variance stabilisation\n",
    "    BMI: Winsoring or capping a high percentile or Use robustscaler or Yeo-Johnson \n",
    "---\n",
    "### ðŸ“ˆ 4. Feature Relationships & Patterns\n",
    "\n",
    "Q: Which categorical features (e.g., `GenHealth`, `PhysicalActivity`, `Smoking`) show visible patterns in relation to `Diabetes_binary`?  \n",
    "A: All the categorical features \n",
    "\n",
    "Q: Are there any strong pairwise relationships or multicollinearity between features?  \n",
    "A:  There is no multicollinearity; there is a weak correlation between the features\n",
    "\n",
    "Q: What trends or correlations stood out during your analysis?  \n",
    "A:  PhysHlth and MentHlth showed a highest but weak correlation (0.35)\n",
    "    BMI and Outcome (0.22)\n",
    "---\n",
    "### ðŸ§° 5. EDA Summary & Preprocessing Plan\n",
    "\n",
    "Q: What are your 3â€“5 biggest takeaways from EDA?  \n",
    "A:  The dataset class is imbalanced, so there is a need to carefully address it to avoid bias in the model.\n",
    "    Near-constant value can be potentially dropped\n",
    "    Outliers should be handled with appropriate scaling\n",
    "\n",
    "Q: Which features will you scale, encode, or exclude in preprocessing?  \n",
    "A:  Scale: BMI, MentHlth, PhysHlth\n",
    "Encoding: Ordinal Categorical features (Income, Age, Education, GenHlth)\n",
    "Q: What does your cleaned dataset look like (rows, columns, shape)?  \n",
    "A:  (229474, 22)\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7054b-fa07-4988-b3f6-515c53f0f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9bf38-fa5c-409c-8d4c-c3787bb1dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # To show the full columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66a0d1-8477-4200-aec9-1ff200736133",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_data = pd.read_csv(\"Dataset/diabetes_binary_health_indicators_BRFSS2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73090877-1bc2-4ada-91aa-f47fd0b24c7c",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c3cb6-bf86-4850-a8a4-635ab28775e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde51c62-529b-4996-84d4-d45c83feb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448355c-9731-4803-8cb9-67b3425d5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593fbbf-f5ba-427e-8c68-899dbb79e294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename the target column\n",
    "diab_data.rename(columns={\"Diabetes_binary\": \"Outcome\"}, inplace=True)\n",
    "diab_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affedb1-922d-4d16-9b08-acb9a1cdbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diab_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2c950-3f4a-46f0-a082-c466b49fc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "diab_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd4683-87fc-4adc-8d45-38184b7bedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the dataset\n",
    "diab_data[diab_data.duplicated()]\n",
    "# diab_data.loc[diab_data.duplicated()] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fcc14-3e16-47d9-95e8-74311224e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_data.dtypes # Incorrectly formatted features as float64, BMI is correct as float, other features are not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3aeda3-4766-4df4-9914-aa7cb65ddc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns which should be categorical or numeric\n",
    "binary_features = []\n",
    "ordinal_features = []\n",
    "numeric_features = [] \n",
    "\n",
    "for col in diab_data.columns:\n",
    "    unique_vals = diab_data[col].nunique()\n",
    "    unique_list = sorted(diab_data[col].unique())\n",
    "\n",
    "    if unique_vals == 2 and set (unique_list)== {0.0, 1.0}:\n",
    "        binary_features.append(col)\n",
    "    elif unique_vals <= 13 and all(isinstance(x, (int, float)) and x == int(x) for x in unique_list):\n",
    "        ordinal_features.append(col)\n",
    "    else:\n",
    "        numeric_features.append(col)\n",
    "print(f\"binary_features (0/1): {binary_features}\")\n",
    "print(f\"ordinal_features: {ordinal_features}\")\n",
    "print(f\"numeric_features: {numeric_features}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca3af3-f3ef-4c43-947c-dffce566769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for constant or near constant features\n",
    "print (\"Variance analysis for constant/ near-constant features:\")\n",
    "print (\"-\"*60)\n",
    "variance_analysis = []\n",
    "for col in diab_data.columns:\n",
    "    unique_vals = diab_data[col].nunique()\n",
    "    most_common_pct = diab_data[col].value_counts().iloc[0]/len(diab_data)*100\n",
    "    variance = diab_data[col].var()\n",
    "    variance_analysis.append({\"column\": col, \"unique_values\":unique_vals, \"most_common_pct\": most_common_pct, \"variance\":variance})\n",
    "variance_df = pd.DataFrame(variance_analysis)\n",
    "variance_df= variance_df.sort_values(\"most_common_pct\", ascending = False)\n",
    "print (\"Features sorted by dominance most common value\")\n",
    "variance_df_display = variance_df.round(2)\n",
    "print(variance_df_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a34d2e-5171-4d86-94d6-7a54702383e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify near-constant features (>95% same value)\n",
    "near_constant = variance_df[variance_df[\"most_common_pct\"]>95]\n",
    "print(f\"\\\n",
    "Near_constant features (>95% same value):\")\n",
    "print(near_constant [[\"column\", \"most_common_pct\"]].round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1a7a0-89ba-4793-98b4-1ffc6fbcc5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4f323-64b8-41b2-a4cb-8f4faf2c9710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target Class Distribution\n",
    "diab_data[\"Outcome\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31158624-2005-45fc-b25f-766953ad3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count and percentage\n",
    "counts = diab_data['Outcome'].value_counts()\n",
    "outcome_percent = round(counts / counts.sum() * 100, 1)\n",
    "\n",
    "# Define legend labels\n",
    "legend_labels = {0: 'No diabetes', 1: 'Diabetes'}\n",
    "legend_labels_list = [legend_labels[i] for i in sorted(legend_labels.keys())]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Bar chart\n",
    "sns.countplot(\n",
    "    data=diab_data,\n",
    "    x='Outcome',\n",
    "    hue='Outcome',\n",
    "    palette='bright',\n",
    "    dodge=False,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Bar Chart')\n",
    "\n",
    "# Replace legend numbers with text\n",
    "axes[0].legend(legend_labels_list, title=\"Outcome\")\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(\n",
    "    counts,\n",
    "    labels=legend_labels_list,\n",
    "    colors=['blue', 'orange'],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90\n",
    ")\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_title('Pie Chart')\n",
    "\n",
    "# Overall title\n",
    "plt.suptitle('Diabetes Outcome Distribution', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b758a49-22ab-456a-9f1c-d34427ff960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded dataset and starting numeric feature analysis...\")\n",
    "# Identify numeric columns with more than 10 unique values (exclude binaries)\n",
    "numeric_rich = [c for c in diab_data.columns if pd.api.types.is_numeric_dtype(diab_data[c]) and diab_data[c].nunique() > 15]\n",
    "print(\"Numeric features with meaningful distributions:\")\n",
    "print(numeric_rich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98abd6-d4a9-4eb5-8a11-ce651f738201",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute distribution stats, skewness, and outliers via IQR\n",
    "rows = []\n",
    "for col in numeric_rich:\n",
    "    s = diab_data[col].dropna()\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    outliers = ((s < lower) | (s > upper)).sum()\n",
    "    skew = s.skew()\n",
    "    kurt = s.kurtosis()\n",
    "    rows.append({\n",
    "        'feature': col,\n",
    "        'min': s.min(),\n",
    "        'q1': q1,\n",
    "        'median': s.median(),\n",
    "        'mean': s.mean(),\n",
    "        'q3': q3,\n",
    "        'max': s.max(),\n",
    "        'std': s.std(),\n",
    "        'skew': skew,\n",
    "        'kurtosis': kurt,\n",
    "        'iqr': iqr,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper,\n",
    "        'outlier_count': outliers,\n",
    "        'outlier_pct': outliers / len(s) * 100\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "summary_round = summary.copy()\n",
    "summary_round[['min','q1','median','mean','q3','max','std','skew','kurtosis','iqr','lower_bound','upper_bound','outlier_pct']] = \\\n",
    "    summary_round[['min','q1','median','mean','q3','max','std','skew','kurtosis','iqr','lower_bound','upper_bound','outlier_pct']].round(2)\n",
    "print(\"\\\n",
    "Distribution, skewness, and outlier summary:\")\n",
    "print(summary_round[['feature','min','q1','median','mean','q3','max','skew','kurtosis','outlier_count','outlier_pct']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095eee05-887d-4493-aaeb-76af8b851015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain-based unrealistic value checks\n",
    "issues = []\n",
    "# MentHlth and PhysHlth should be 0-30 days\n",
    "for col in ['MentHlth','PhysHlth']:\n",
    "    if col in diab_data.columns:\n",
    "        below0 = (diab_data[col] < 0).sum()\n",
    "        above30 = (diab_data[col] > 30).sum()\n",
    "        issues.append({'feature': col, 'below_0': int(below0), 'above_30': int(above30)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1699f9-c813-4ae6-a9c6-a4e688e9d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI plausible rough bounds [10, 80] (very conservative)\n",
    "if 'BMI' in diab_data.columns:\n",
    "    bmi_below10 = (diab_data['BMI'] < 10).sum()\n",
    "    bmi_above80 = (diab_data['BMI'] > 80).sum()\n",
    "    issues.append({'feature': 'BMI', 'below_0': int((diab_data['BMI'] < 0).sum()), 'below_10': int(bmi_below10), 'above_80': int(bmi_above80)})\n",
    "\n",
    "issues_df = pd.DataFrame(issues)\n",
    "print(\"\\\n",
    "Unrealistic or problematic value checks:\")\n",
    "print(issues_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba478b1-f575-4428-94ab-6edd6b64540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations: Histograms and Boxplots for the main continuous/count features\n",
    "plot_cols = [c for c in ['BMI','MentHlth','PhysHlth'] if c in diab_data.columns]\n",
    "\n",
    "for col in plot_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(diab_data[col], bins=30, kde=True, color='steelblue')\n",
    "    plt.title('Histogram of ' + col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for col in plot_cols:\n",
    "    plt.figure(figsize=(6,2.5))\n",
    "    sns.boxplot(x=diab_data[col], color='coral')\n",
    "    plt.title('Boxplot of ' + col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Generated summary tables and plots for BMI, MentHlth, and PhysHlth.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a3445-da06-465d-9412-0fd7b2263dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adb0e3-f658-475a-b8a4-3c69225cef44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77baa358-cc65-4517-bc2c-566d06b958a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4b2b4-daa3-43a8-aeed-97ddaee07cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations: Bar plots for key categorical features vs diabetes rate\n",
    "#plot_features = ['GenHlth','PhysActivity','HighBP','HighChol','Income']\n",
    "features = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex', 'GenHlth', 'Age', 'Education', 'Income']\n",
    "for feat in features:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    rates = diab_data.groupby(feat)['Outcome'].mean().reset_index()\n",
    "    rates['DiabetesRate_pct'] = rates['Outcome'] * 100\n",
    "    sns.barplot(data=rates, x=feat, y='DiabetesRate_pct', palette='viridis')\n",
    "    plt.ylabel('Diabetes rate (%)')\n",
    "    plt.title('Diabetes rate by ' + str(feat))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Generated bar plots for categorical features vs diabetes rate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a7084-fdd0-4101-8fa6-297c07466bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c980b-04cf-4dfd-8911-8ccd87c2a5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#corr_matrix = diab_data[[\"BMI\", \"MentHlth\", \"PhysHlth\", \"Income\", \"Age\", \"Education\", \"GenHlth\"]].corr(method = \"pearson\")\n",
    "corr_matrix = diab_data[[\"BMI\", \"MentHlth\", \"PhysHlth\", \"Outcome\"]].corr(method = \"pearson\")         \n",
    "# Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967c1f2-e7e4-43ae-9b18-90aa76c29054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e1938-88fa-4886-ac07-b09cb7e54609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "720f74ce-a618-497e-a376-3e947961abc0",
   "metadata": {},
   "source": [
    "### Convert into appropriate datatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edf87f-d334-4f01-acc9-44b393487bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features : ['Outcome', 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex']\n",
    "ordinal_features: ['GenHlth', 'Age', 'Education', 'Income']\n",
    "numeric_features: ['BMI', 'MentHlth', 'PhysHlth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbec1e-58ae-4847-82c5-df42ad15573c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61a709b7-5ffa-4714-8682-00c49bccf987",
   "metadata": {},
   "source": [
    "### Check for skewness\n",
    "> +1 or < -1 â†’ highly skewed\n",
    "Between Â±0.5 and Â±1 â†’ moderately skewed\n",
    "Between -0.5 and +0.5 â†’ approximately symmetric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271878ca-d60d-4aed-bc65-01e1a4290e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bf0f5-b475-46e6-8303-03078054caa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0db4e4-aa90-4459-b064-4702a9bc8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324a7c1-201f-42ee-a11d-c45ff27ed91b",
   "metadata": {},
   "source": [
    "### Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0b638-dfd3-4699-9807-0a1d4baa3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = diab_data.select_dtypes(include=['int', 'float']).columns.drop('Outcome')\n",
    "for col in numeric_cols:\n",
    "    sns.histplot(data=diab_data, x=col, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f9051f-db6b-4874-8c72-722b62f5a631",
   "metadata": {},
   "source": [
    "## Categorical Feature Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0e9da-3799-4f38-92e5-e76eb96a80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = diab_data.select_dtypes(include='category').columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    diab_data[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f'Frequency of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df514e-dec4-405f-b448-a98171b6ca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce45683-84f2-46e3-ad81-c5725293eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-Biserial Correlation (for binary vs continuous)\n",
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "for col in diab_data.select_dtypes(include=['int', 'float']).columns:\n",
    "    if col != 'Outcome':\n",
    "        r, p = pointbiserialr(diab_data['Outcome'], diab_data[col])\n",
    "        print(f\"{col}: r = {r:.3f}, p = {p:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cc94c-fad7-40d5-b36e-fe298af7ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CramÃ©râ€™s V (for categorical vs categorical)\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "for col in diab_data.select_dtypes(include='category').columns:\n",
    "    v = cramers_v(diab_data[col], diab_data['Outcome'])\n",
    "    print(f\"{col}: CramÃ©râ€™s V = {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664e659-a9c2-4452-a03d-e3edd4b6af15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c83d0c-e0d8-468f-85a5-47664f54d747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35155c6-cf37-4893-8123-081aca2e9921",
   "metadata": {},
   "source": [
    "### Identifying predictive numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309cd676-02b6-43bd-a573-63cd5c74c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = diab_data[['BMI', 'MentHlth', 'PhysHlth', 'Outcome']].corr()\n",
    "# Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1fe3e-fe4d-4b1a-b7a4-adcd83dfbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance_inflation_factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Ensure no categorical variables (encode them if needed)\n",
    "X = diab_data.drop(columns=['Outcome'])  # exclude target\n",
    "X = add_constant(X)\n",
    "\n",
    "# Calculate VIF\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Feature\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif = vif.sort_values(by=\"VIF\", ascending=False)\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafc3a5-78d5-456e-840a-0cc7aa069997",
   "metadata": {},
   "source": [
    "### Identifying predictive categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314f4d4-8ea1-44ad-99c6-7c06a9522e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Loop through each categorical column and plot\n",
    "for col in cat_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # Plot average proportion of diabetes by category\n",
    "    sns.barplot(\n",
    "        x=col, \n",
    "        y='Outcome', \n",
    "        data=diab_data, \n",
    "        estimator=lambda x: sum(x) / len(x),\n",
    "        palette='coolwarm'\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Proportion of Diabetes Cases by {col}\", fontsize=12)\n",
    "    plt.ylabel(\"Proportion with Diabetes\")\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adf99a-b9ab-4d16-bcf5-061ec45b696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HighBP, HighChol, CholCheck, Smoking, Stroke, HeartDiseaseorattack, AnyHealthCare, NoDocscCost, GenHealth, DiffWalk, Sex\n",
    "\n",
    "HighBP, Age, Sex, DiffWalk, GenHlth, NoDocbcCost, AnyHealthcare, HvyAlcoholConsump Veggies, Fruits, PhysActivity, HeartDiseaseorAttack, Stroke, Smoker, CholCheck, HighChol, Education, Income    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ec716-27c7-42b3-bf60-14a1bd1b4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Replace this with your actual DataFrame name if different\n",
    "df = diab_data.copy()\n",
    "# Store results\n",
    "chi2_results = []\n",
    "\n",
    "for feature in cat_features:\n",
    "    contingency_table = pd.crosstab(df[feature], df[target])\n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    chi2_results.append({\n",
    "        'Feature': feature,\n",
    "        'Chi2 Stat': round(chi2_stat, 2),\n",
    "        'p-value': round(p_value, 5),\n",
    "        'Significant (p < 0.05)': p_value < 0.05\n",
    "    })\n",
    "\n",
    "# Display as a DataFrame\n",
    "chi2_df = pd.DataFrame(chi2_results)\n",
    "print(chi2_df.sort_values(by='p-value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd29465-a828-4542-8603-86c2c10691bb",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc7175-a936-4648-ab53-1102b041cb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be157a5b-14f7-4a10-8eae-eed8d547ed22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b30cce-a139-42d7-b1f1-dc1f4d1a9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_column = diab_data.iloc[:, 1:]\n",
    "#features_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b2dca-6de9-4f83-b80c-7ab524bb3bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
